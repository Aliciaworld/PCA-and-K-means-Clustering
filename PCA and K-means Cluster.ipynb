{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERAL ROUTINE FOR COMBINING PCA WITH K-MEANS CLUSTERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why combine PCA with K-means Clustering?\n",
    "By reducing the number of features(PCA reduced the features numbers by combining them into bigger, more meanningful features), we can not only improve the performance of the algorithm but also reduce the noise. In this notebook, I will introduce how to combine PCA and k-means cluster together in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Preprocessing Data](#preprocessingdata)\n",
    "- [Performing Dimensionality Reduction with PCA](#performingdimensionalityreductionwithpca)\n",
    "- [Determine the number of K-Means clusters](#determinethenumberofclusters)\n",
    "- [Combine PCA and K-means Cluster](#combinepcaandkmeanscluster)\n",
    "- [Analysis the results](analysistheresults)\n",
    "- [Visualize Clusters by Components](visualizeclustersbycomponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='preprocessingdata'></a>\n",
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "\n",
    "## If the range of variables has a vast difference, We should first standardize them firstly. \n",
    "## Otherwise, because of the mathematical nature of modeling, it would disregard the smaller one variable.\n",
    "## To treat all the features equally, we transform all the variables to make their values fall within the same numerical range.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_std = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='performingdimensionalityreductionwithpca'></a>\n",
    "## Performing Dimensionality Reduction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform dimensionality reduction with PCA-1\n",
    "\n",
    "## (1) fit the standardized data (data-std) using PCA\n",
    "pca = PCA(n_components=???)\n",
    "pca.fit(data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform dimensionality reduction with PCA-2\n",
    "\n",
    "## (2) decide how many features we'd like to keep\n",
    "## 2.1 method based on cumulative variance plot\n",
    "pca.explained_variance_ratio_\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(range(1,pca.n_components_), pca.explained_variance_ratio_.cumsum(), marker='o', linestyle ='--')\n",
    "plt.title('-------')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "\n",
    "# The figure will show the amount of variances captured depending on the number of componenets. \n",
    "# A rule of thumbe is to preserve about 80% of the variances.(80% of y). We temporatily use @ to denote the chosen number\n",
    "\n",
    "## 2.2 medthod based on the relatively ratio\n",
    "plt.bar(range(1,number of features), pca.explained_variance_ratio_)\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('variance %')\n",
    "plt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform dimensionality reduction with PCA-3\n",
    "\n",
    "## (3) perform PCA with the chosen number of components\n",
    "pca = PCA(n_components = @)\n",
    "pca.fit(data_std)\n",
    "pca.transform(data_std)\n",
    "\n",
    "pca_scores = pca.transform(data_std)\n",
    "\n",
    "# The components' scores are stored in the pca_scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='determinenumberofclusters'></a>\n",
    "## Determine the number of K-Means clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of clusters in K-means algorithm\n",
    "\n",
    "## In order to determine the number of clusters in K-means algorithm, we run the algorithem with different numbers and determine the SUM of Squares for each one.\n",
    "## Based on the values of SUM of Squares and the Elbow method, we made a decision.\n",
    "## We decide how many clustering we'd test according to data.\n",
    "\n",
    "ss = []\n",
    "for i in range(1,number of clusters):\n",
    "    kmeans_pca = KMeans(n_clusters = i, random_state=42)\n",
    "    kmeans_pca.fit(pca_scores)\n",
    "    ss.append(kmeans_pca.inertia_)\n",
    "## inertia_: Sum of squared distances of samples to their closest cluster center.\n",
    "\n",
    "plt.figure(figsize(10, 8))\n",
    "plt.plot(range(1, number of clusters), ss, marker='o', linestyle = '--')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('SS')\n",
    "plt.title('K-means with PCA Cluster')\n",
    "\n",
    "## using elbow method to determine the number of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='combinepcaandkmeanscluster'></a>\n",
    "## Combine PCA and K-means Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine K-Means with PCA\n",
    "kmeans_pca = KMeans(n_cluster = @, random_state = 42)\n",
    "kmeans_pca.fit(pca_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='analysistheresults'></a>\n",
    "## Analysis the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means clustering with PCA results\n",
    "## create a new dataframe with the original features and pca scores and assigned clusters.\n",
    "data_pca_kmeans = pd.concat([data, pd.DataFrame(pca_scores)], axis=1)\n",
    "data_pca_kmeans.columns.values[-@:] = ['Component 1', 'Component 2', 'Component 3',...]\n",
    "\n",
    "data_pca_kmeans['Labels'] = kmeans_pca.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the names of the segments to the labels\n",
    "data_pca_kmeans['labels'] = data_pca_kmeans['labels'].map({0:'first', 1:'second', 2:'third'...})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='visualizeclustersbycomponents'></a>\n",
    "## Visualize Clusters by Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we hope to visualize the clusters on a 2D plane, we need to choose two components. PCA has already determined the most important compoenets for us. We just need to choose the very first two.\n",
    "x_axis = data_pca_kmeans['Component 2']\n",
    "y_axis = data_pca_kmeans['Component 1']\n",
    "\n",
    "plt.figure(figsize = (10,8))\n",
    "sns.scatterplot(x_axis,y_axis, hue=data_pca_kmeans['labels'], palette = ['g','r','c','m'])\n",
    "plt.title('Clusters by PCA Components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
